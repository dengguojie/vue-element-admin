# Copyright 2020 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""
dynamic operator
"""
# 'pylint: disable=W0622
from __future__ import absolute_import as _abs
from .addcdiv import addcdiv
from .aipp import aipp
from .avg_pool_1d import avg_pool_1d
from .avg_pool import avg_pool
from .pad_v3_grad import pad_v3_grad
from .avg_pool_grad import avg_pool_grad
from .embedding_dense_grad import embedding_dense_grad
from .one_hot import one_hot
from .rnn_gen_mask_v2 import rnn_gen_mask_v2
from .apply_proximal_adagrad_d import apply_proximal_adagrad_d
from .arg_max_v2 import arg_max_v2
from .arg_min import arg_min
from .mirror_pad import mirror_pad
from .arg_max_with_value import arg_max_with_value
from .arg_min_with_value import arg_min_with_value
from .avg_pool3d import avg_pool3d
from .avg_pool3d_grad import avg_pool3d_grad
from .ascend_quant import ascend_quant
from .broadcast_to import broadcast_to
from .softsign import softsign
from .diag import diag
from .softplus_grad import softplus_grad
from .softplus import softplus
from .diag_part import diag_part
from .unsorted_segment_sum import unsorted_segment_sum
from .fused_mul_add import fused_mul_add
from .div_no_nan import div_no_nan
from .unsorted_segment_min import unsorted_segment_min
from .unsorted_segment_max import unsorted_segment_max
from .unsorted_segment_prod import unsorted_segment_prod
from .gather_nd import gather_nd
from .apply_adagrad_da_d import apply_adagrad_da_d
from .gather import gather
from .gather_v2 import gather_v2
from .max_pool_grad import max_pool_grad
from .kl_div import kl_div
from .inplace_update import inplace_update
from .add_mat_mat_elements import add_mat_mat_elements
from .tile_with_axis import tile_with_axis
from .bias import bias
from .segment_sum import segment_sum
from .dequantize import dequantize
from .dynamic_rnn_v2 import dynamic_rnn_v2
from .bninference_d import bninference_d
from .bn_training_reduce import bn_training_reduce
from .bounding_box_decode import bounding_box_decode
from .scatter_nd import scatter_nd
from .scatter_add import scatter_add
from .scatter_update import scatter_update
from .scatter_sub import scatter_sub
from .scatter_max import scatter_max
from .scatter_min import scatter_min
from .scatter_mul import scatter_mul
from .scatter_div import scatter_div
from .scatter_nd_add import scatter_nd_add
from .scatter_nd_sub import scatter_nd_sub
from .scatter_nd_update import scatter_nd_update
from .equal import equal
from .sigmoid_cross_entropy_with_logits_grad import sigmoid_cross_entropy_with_logits_grad
from .relu import relu
from .relu_v2 import relu_v2
from .relu_grad_v2 import relu_grad_v2
from .apply_adadelta_d import apply_adadelta_d
from .relu6_d import relu6_d
from .adam_apply_one_assign import adam_apply_one_assign
from .sigmoid_cross_entropy_with_logits_grad_v2 import sigmoid_cross_entropy_with_logits_grad_v2
from .add import add
from .rsqrt_grad import rsqrt_grad
from .inv import inv
from .gelu import gelu
from .smooth_l1_loss_grad import smooth_l1_loss_grad
from .smooth_l1_loss_grad_v2 import smooth_l1_loss_grad_v2
from .fast_gelu import fast_gelu
from .axpy import axpy
from .axpy_v2 import axpy_v2
from .floor_mod import floor_mod
from .mul import mul
from .threshold_grad_v2_d import threshold_grad_v2_d
from .invert import invert
from .muls import muls
from .reduce_sum import reduce_sum
from .reduce_sum_d import reduce_sum_d
from .reduce_max_d import reduce_max_d
from .reduce_mean import reduce_mean
from .reduce_min import reduce_min
from .reduce_mean_d import reduce_mean_d
from .reduce_std_with_mean import reduce_std_with_mean
from .resize_nearest_neighbor_v2 import resize_nearest_neighbor_v2
from .reverse_v2 import reverse_v2
from .conv2d import conv2d
from .depthwise_conv2d import depthwise_conv2d
from .conv3d import conv3d
from .conv3d_backprop_input import conv3d_backprop_input
from .conv3d_backprop_input import check_and_config_para
from .conv3d_transpose import conv3d_transpose
from .conv3d_backprop_filter import conv3d_backprop_filter
from .dynamic_atomic_addr_clean import dynamic_atomic_addr_clean
from .sparse_apply_ftrl_d import sparse_apply_ftrl_d
from .sparse_apply_adagrad_v2_d import sparse_apply_adagrad_v2_d
from .sparse_apply_adadelta_d import sparse_apply_adadelta_d
from .sparse_apply_adagrad_d import sparse_apply_adagrad_d
from .sparse_apply_ftrl_v2_d import sparse_apply_ftrl_v2_d
from .sparse_apply_rms_prop_d import sparse_apply_rms_prop_d
from .div import div
from .sqrt import sqrt
from .threshold_v2_d import threshold_v2_d
from .square import square
from .squared_difference import squared_difference
from .sparse_apply_proximal_adagrad_d import sparse_apply_proximal_adagrad_d
from .maximum import maximum
from .minimum import minimum
from .sigmoid_cross_entropy_with_logits_v2 import sigmoid_cross_entropy_with_logits_v2
from .accumulate_nv2 import accumulate_nv2
from .adam_apply_one import adam_apply_one
from .adam_apply_one_with_decay import adam_apply_one_with_decay
from .adam_apply_one_with_decay_assign import adam_apply_one_with_decay_assign
from .add_n import add_n
from .rsqrt import rsqrt
from .lru_cache_v2 import lru_cache_v2
from .greater_equal import greater_equal
from .apply_gradient_descent import apply_gradient_descent
from .layer_norm_beta_gamma_backprop import layer_norm_beta_gamma_backprop
from .layer_norm_beta_gamma_backprop_v2 import layer_norm_beta_gamma_backprop_v2
from .less import less
from .less_equal import less_equal
from .floor_div import floor_div
from .fast_gelu_grad import fast_gelu_grad
from .smooth_l1_loss import smooth_l1_loss
from .gelu_grad import gelu_grad
from .fused_mul_add_n import fused_mul_add_n
from .fused_mul_apply_momentum import fused_mul_apply_momentum
from .apply_keras_momentum_d import apply_keras_momentum_d
from .apply_power_sign_d import apply_power_sign_d
from .apply_rms_prop_d import apply_rms_prop_d
from .apply_add_sign_d import apply_add_sign_d
from .apply_adam_with_amsgrad_d import apply_adam_with_amsgrad_d
from .square_sum_v1 import square_sum_v1
from .tile_d import tile_d
from .tile import tile
from .apply_adam_d import apply_adam_d
from .logical_or import logical_or
from .real_div import real_div
from .reciprocal import reciprocal
from .concat_offset import concat_offset
from .neg import neg
from .concat_d import concat_d
from .concat_v2_d import concat_v2_d
from .pack import pack
from .strided_slice import strided_slice
from .slice import slice
from .cast import cast
from .exp import exp
from .leaky_relu_grad import leaky_relu_grad
from .log1p import log1p
from .sigmoid_grad import sigmoid_grad
from .sqrt_grad import sqrt_grad
from .zeros_like import zeros_like
from .depthwise_conv2d_backprop_input import depthwise_conv2d_backprop_input
from .depthwise_conv2d_backprop_filter import depthwise_conv2d_backprop_filter
from .conv2d_backprop_input import conv2d_backprop_input
from .conv2d_backprop_filter import conv2d_backprop_filter
from .conv2d_transpose import conv2d_transpose
from .deconvolution import deconvolution
from .mat_mul import mat_mul
from .batch_matmul import batch_matmul
from .batch_matmul_v2 import batch_matmul_v2
from .sub import sub
from .transpose import transpose
from .as_strided import as_strided
from .trans_data import trans_data
from .unpack import unpack
from .batch_multi_class_non_max_suppression import batch_multi_class_non_max_suppression
from .top_k_d import top_k_d
from .in_top_k import in_top_k
from .apply_adagrad_d import apply_adagrad_d
from .top_k_v2_d import top_k_v2_d
from .pad_d import pad_d
from .pad import pad
from .pad_v3 import pad_v3
from .split_d import split_d
from .split import split
from .split_v import split_v
from .strided_slice_grad import strided_slice_grad
from .fill import fill
from .fills import fills
from .drop_out_do_mask import drop_out_do_mask
from .hardtanh_grad import hardtanh_grad
from .tanh import tanh
from .inv_grad import inv_grad
from .sigmoid_cross_entropy_with_logits import sigmoid_cross_entropy_with_logits
from .abs import abs
from .approximate_equal import approximate_equal
from .acos import acos
from .apply_proximal_gradient_descent import apply_proximal_gradient_descent
from .apply_centered_rms_prop_d import apply_centered_rms_prop_d
from .apply_ftrl_d import apply_ftrl_d
from .apply_ftrl_v2_d import apply_ftrl_v2_d
from .apply_momentum_d import apply_momentum_d
from .assign import assign
from .assign_add import assign_add
from .bias_add import bias_add
from .bias_add_grad import bias_add_grad
from .batch_to_space import batch_to_space
from .apply_ada_max_d import apply_ada_max_d
from .apply_adagradv2_d import apply_adagradv2_d
from .batch_to_space_nd import batch_to_space_nd
from .space_to_batch import space_to_batch
from .space_to_batch_nd import space_to_batch_nd
from .depth_to_space import depth_to_space
from .space_to_depth import space_to_depth
from .greater import greater
from .l2_loss import l2_loss
from .expand import expand
from .log import log
from .logical_and import logical_and
from .logical_not import logical_not
from .reduce_all import reduce_all
from .reduce_any import reduce_any
from .reduce_prod import reduce_prod
from .relu6 import relu6
from .relu6_grad import relu6_grad
from .relu_grad import relu_grad
from .select import select
from .select_v2 import select_v2
from .max_pool import max_pool
from .sign import sign
from .acosh import acosh
from .adds import adds
from .asin import asin
from .asin_grad import asin_grad
from .ones_like import ones_like
from .ceil import ceil
from .cos import cos
from .cosh import cosh
from .sigmoid import sigmoid
from .sin import sin
from .sinh import sinh
from .tan import tan
from .scale import scale
from .asinh import asinh
from .asinh_grad import asinh_grad
from .expm1 import expm1
from .mse_loss import mse_loss
from .dynamic_rnn import dynamic_rnn
from .mse_loss_grad import mse_loss_grad
from .floor import floor
from .rint import rint
from .round import round
from .leaky_relu import leaky_relu
from .mod import mod
from .power import power
from .pow import pow
from .truncate_div import truncate_div
from .truncate_mod import truncate_mod
from .dynamic_lstm_grad_cell import dynamic_lstm_grad_cell
from .xdivy import xdivy
from .xlogy import xlogy
from .atan import atan
from .atanh import atanh
from .assign_sub import assign_sub
from .atan_grad import atan_grad
from .tanh_grad import tanh_grad
from .abs_grad import abs_grad
from .acos_grad import acos_grad
from .acosh_grad import acosh_grad
from .nms_with_mask import nms_with_mask
from .mul_no_nan import mul_no_nan
from .reduce_max import reduce_max
from .maximum_grad import maximum_grad
from .minimum_grad import minimum_grad
from .atan2 import atan2
from .reciprocal_grad import reciprocal_grad
from .not_equal import not_equal
from .erf import erf
from .erfc import erfc
from .roi_align_grad import roi_align_grad
from .roi_align import roi_align
from .data_format_dim_map import data_format_dim_map
from .elu import elu
from .bn_infer import bn_infer
from .bn_infer_grad import bn_infer_grad
from .selu import selu
from .binary_cross_entropy import binary_cross_entropy
from .binary_cross_entropy_grad import binary_cross_entropy_grad
from .softmax_v2 import softmax_v2
from .softmax_grad import softmax_grad
from .bn_training_reduce_grad import bn_training_reduce_grad
from .log_softmax_v2 import log_softmax_v2
from .log_softmax_grad import log_softmax_grad
from .layer_norm_x_backprop import layer_norm_x_backprop
from .layer_norm_x_backprop_v2 import layer_norm_x_backprop_v2
from .masked_fill import masked_fill
from .resize_bilinear_v2 import resize_bilinear_v2
from .resize_bilinear_v2_grad import resize_bilinear_v2_grad
from .elu_grad import elu_grad
from .bessel_i0e import bessel_i0e
from .flatten import flatten
from .tensor_move import tensor_move
from .bessel_i1e import bessel_i1e
from .bitwise_and import bitwise_and
from .bitwise_or import bitwise_or
from .bitwise_xor import bitwise_xor
from .prelu import prelu
from .max_pool_with_argmaxv1 import max_pool_with_argmax_v1
from .lars_v2_update import lars_v2_update
from .clip_by_value import clip_by_value
from .clip_by_norm_no_div_sum import clip_by_norm_no_div_sum
from .eltwise import eltwise
from .iou import iou
from .bn_training_update import bn_training_update
from .bn_training_update_v3 import bn_training_update_v3
from .softmax_cross_entropy_with_logits import softmax_cross_entropy_with_logits
from .resize_nearest_neighbor_v2_grad import resize_nearest_neighbor_v2_grad
from .layer_norm import layer_norm
from .layer_norm_grad import layer_norm_grad
from .l1_loss_grad import l1_loss_grad
from .bn_training_update_grad import bn_training_update_grad
from .lp_loss import lp_loss
from .lp_norm_reduce import lp_norm_reduce
from .lp_norm_update import lp_norm_update
from .lp_norm import lp_norm
from .masked_scale import masked_scale
from .scatter_non_aliasing_add import scatter_non_aliasing_add
from .ger import ger
from .smooth_l1_loss_v2 import smooth_l1_loss_v2
from .index_fill_d import index_fill_d
from .max_pool_grad_with_argmaxv1 import max_pool_grad_with_argmax_v1
from .max_pool_grad_with_argmaxv2 import max_pool_grad_with_argmax_v2
from .nll_loss import nll_loss
from .nll_loss_grad import nll_loss_grad
from .shrink import shrink
from .addcmul import addcmul
from .confusion_softmax_grad import confusion_softmax_grad
from .sort import sort
from .acts_ulq import acts_ulq
from .acts_ulq_input_grad import acts_ulq_input_grad
from .act_ulq_clamp_max_grad import act_ulq_clamp_max_grad
from .act_ulq_clamp_min_grad import act_ulq_clamp_min_grad
from .wts_arq import wts_arq
from .ifmr import ifmr
from .inplace_index_add import inplace_index_add
from .square_sum_all import square_sum_all
from .pad_v2 import pad_v2
from .scan_pq_codes import scan_pq_codes
from .tabulate_fusion_grad import tabulate_fusion_grad
from .ascend_dequant import ascend_dequant
from .ascend_dequant_s16 import ascend_dequant_s16
from .ascend_requant import ascend_requant
from .ascend_requant_s16 import ascend_requant_s16
from .ascend_anti_quant import ascend_anti_quant
from .avg_pool_v2 import avg_pool_v2
from .global_lppool import global_lppool
from .is_finite import is_finite
from .non_zero import non_zero
from .max_pool_v3 import max_pool_v3
from .gen_adc import gen_adc
from .prod_virial_se_a import prod_virial_se_a
from .swish import swish
from .hard_swish import hard_swish
from .strided_slice_v3 import strided_slice_v3
from .tabulate_fusion import tabulate_fusion
from .swish_grad import swish_grad
from .hard_swish_grad import hard_swish_grad
from .dynamic_gru_v2 import dynamic_gru_v2
from .sync_batch_norm_backward_reduce import sync_batch_norm_backward_reduce
from .sync_batch_norm_backward_elemt import sync_batch_norm_backward_elemt
from .fake_quant_with_min_max_vars import fake_quant_with_min_max_vars
from .get_shape import get_shape
from .prod_env_mat_a import prod_env_mat_a
from .max_pool_with_argmaxv2 import max_pool_with_argmax_v2
from .sync_bn_training_update import sync_bn_training_update
from .sync_batch_norm_gather_stats_with_counts import sync_batch_norm_gather_stats_with_counts
from .reduce_mean_with_count import reduce_mean_with_count
from .prod_force_se_a import prod_force_se_a
from .moving_sum_with_sigmoid import moving_sum_with_sigmoid
